{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* YOLO拥有75个卷积层，还有跳过连接和上采样层。它不使用任何形式的池化，使用步幅为 2 的卷积层对特征图进行下采样。这有助于防止通常由池化导致的低级特征丢失。\n",
    "* 卷积层所学习的特征会被传递到分类器/回归器，从而进行预测（边界框的坐标、类别标签等）\n",
    "* 在 YOLO 中，预测是通过卷积层完成的其核心尺寸为：1×1×(B×(5+C))(分别描述每个边界框的中心坐标、维度、objectness 分数和 C 类置信度), 预测B个框每个框有5个参数和C个类别的预测概率\n",
    "* 预测图就是每个可以预测固定数量边界框的单元格\n",
    "* 如果对象的中心(其实就是ground truth方框的中心)位于单元格的感受野内，你会希望特征图的每个单元格都可以通过其中一个边界框预测对象\n",
    "* ![预测对像的示意图](./2.jpg )\n",
    "* 红色单元格是网格中第七行的第七个。我们现在使特征图中第七行第七个单元格（特征图中的对应单元格）作为检测狗的单元.现在，这个单元格可以预测三个边界框。哪个将会分配给狗的真值标签(预测边界框的宽度和高度看起来非常合理，但在实践中，训练会带来不稳定的梯度。所以，现在大部分目标检测器都是预测对数空间（log-space）变换，或者预测与预训练默认边界框（即锚点）之间的偏移)负责检测狗的边界框的锚点有最高的 IoU，且有真值框\n",
    "* 下面公式描述了网络输出是如何转换的，以获得边界框的预测结果\n",
    "* ![网络输出的转换公式](./3.jpg)\n",
    "* 正常情况下，YOLO 不会预测边界框中心的确切坐标。它预测：与预测目标的网格单元左上角相关的偏移；使用特征图单元的维度(1)进行归一化的偏移。以我们的图像为例。如果中心的预测是 (0.4, 0.7)，则中心在 13 x 13 特征图上的坐标是 (6.4, 6.7)（红色单元的左上角坐标是 (6,6)）\n",
    "* 但是，如果预测到的 x,y 坐标大于 1，比如 (1.2, 0.7)。那么中心坐标是 (7.2, 6.7)。注意该中心在红色单元右侧的单元中，或第 7 行的第 8 个单元。这打破了 YOLO 背后的理论，因为如果我们假设红色框负责预测目标狗，那么狗的中心必须在红色单元中，不应该在它旁边的网格单元中。因此，为了解决这个问题，我们对输出执行 sigmoid 函数，将输出压缩到区间 0 到 1 之间，有效确保中心处于执行预测的网格单元中\n",
    "* 得出的预测 bw 和 bh 使用图像的高和宽进行归一化。即，如果包含目标（狗）的框的预测 bx 和 by 是 (0.3, 0.8)，那么 13 x 13 特征图的实际宽和高是 (13 x 0.3, 13 x 0.8)\n",
    "* ![检测器输出在最终预测之前的变换过程](./4.jpg)\n",
    "* Object 分数表示目标在边界框内的概率。红色网格和相邻网格的 Object 分数应该接近 1，而角落处的网格的 Object 分数可能接近 0。objectness 分数的计算也使用 sigmoid 函数，因此它可以被理解为概率。\n",
    "* 类别置信度表示检测到的对象属于某个类别的概率（如狗、猫、香蕉、汽车等）。在 v3 之前，YOLO 需要对类别分数执行 softmax 函数操作。但是，YOLO v3 舍弃了这种设计，作者选择使用 sigmoid 函数。因为对类别分数执行 softmax 操作的前提是类别是互斥的。简言之，如果对象属于一个类别，那么必须确保其不属于另一个类别。这在我们设置检测器的 COCO 数据集上是正确的。但是，当出现类别「女性」（Women）和「人」（Person）时，该假设不可行。这就是作者选择不使用 Softmax 激活函数的原因\n",
    "* YOLO v3 在 3 个不同尺度上进行预测。检测层用于在三个不同大小的特征图上执行预测，特征图步幅分别是 32、16、8。这意味着，当输入图像大小是 416 x 416 时，我们在尺度 13 x 13、26 x 26 和 52 x 52 上执行检测\n",
    "* 该网络在第一个检测层之前对输入图像执行下采样，检测层使用步幅为 32 的层的特征图执行检测。随后在执行因子为 2 的上采样后，并与前一个层的特征图（特征图大小相同）拼接。另一个检测在步幅为 16 的层中执行。重复同样的上采样步骤，最后一个检测在步幅为 8 的层中执行。在每个尺度上，每个单元使用 3 个锚点预测 3 个边界框，锚点的总数为 9（不同尺度的锚点不同）。\n",
    "![不同特征图上上采样预测](./5.jpg)\n",
    "* 对于大小为 416 x 416 的图像，YOLO 预测 ((52 x 52) + (26 x 26) + 13 x 13)) x 3 = 10647 个边界框。但是，我们的示例中只有一个对象——一只狗。那么我们怎么才能将检测次数从 10647 减少到 1 呢？目标置信度阈值：首先，我们根据它们的 objectness 分数过滤边界框。通常，分数低于阈值的边界框会被忽略。非极大值抑制：非极大值抑制（NMS）可解决对同一个图像的多次检测的问题。例如，红色网格单元的 3 个边界框可以检测一个框，或者临近网格可检测相同对象。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--images IMAGES] [--det DET] [--bs BS]\n",
      "                             [--confidence CONFIDENCE]\n",
      "                             [--nms_thresh NMS_THRESH] [--cfg CFGFILE]\n",
      "                             [--weights WEIGHTSFILE] [--reso RESO]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\King\\AppData\\Roaming\\jupyter\\runtime\\kernel-737b3e1c-50b7-4880-8820-e9db0a3d0fd7.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2870: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from darknet import *\n",
    "from util import predict_transform\n",
    "import cv2\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'angle': '0',\n",
       "  'batch': '1',\n",
       "  'burn_in': '1000',\n",
       "  'channels': '3',\n",
       "  'decay': '0.0005',\n",
       "  'exposure': '1.5',\n",
       "  'height': '416',\n",
       "  'hue': '.1',\n",
       "  'learning_rate': '0.001',\n",
       "  'max_batches': '500200',\n",
       "  'momentum': '0.9',\n",
       "  'policy': 'steps',\n",
       "  'saturation': '1.5',\n",
       "  'scales': '.1,.1',\n",
       "  'steps': '400000,450000',\n",
       "  'subdivisions': '1',\n",
       "  'width': '416'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '32',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '64',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '2',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '32',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '64',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'linear', 'from': '-3', 'type': 'shortcut'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '2',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '64',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'linear', 'from': '-3', 'type': 'shortcut'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '64',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'linear', 'from': '-3', 'type': 'shortcut'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '2',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'linear', 'from': '-3', 'type': 'shortcut'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'linear', 'from': '-3', 'type': 'shortcut'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'linear', 'from': '-3', 'type': 'shortcut'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'linear', 'from': '-3', 'type': 'shortcut'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'linear', 'from': '-3', 'type': 'shortcut'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'linear', 'from': '-3', 'type': 'shortcut'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'linear', 'from': '-3', 'type': 'shortcut'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'linear', 'from': '-3', 'type': 'shortcut'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '2',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'linear', 'from': '-3', 'type': 'shortcut'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'linear', 'from': '-3', 'type': 'shortcut'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'linear', 'from': '-3', 'type': 'shortcut'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'linear', 'from': '-3', 'type': 'shortcut'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'linear', 'from': '-3', 'type': 'shortcut'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'linear', 'from': '-3', 'type': 'shortcut'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'linear', 'from': '-3', 'type': 'shortcut'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'linear', 'from': '-3', 'type': 'shortcut'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '1024',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '2',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '1024',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'linear', 'from': '-3', 'type': 'shortcut'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '1024',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'linear', 'from': '-3', 'type': 'shortcut'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '1024',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'linear', 'from': '-3', 'type': 'shortcut'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '1024',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'linear', 'from': '-3', 'type': 'shortcut'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '1024',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '1024',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '1024',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'linear',\n",
       "  'filters': '255',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'anchors': '10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326',\n",
       "  'classes': '80',\n",
       "  'ignore_thresh': '.5',\n",
       "  'jitter': '.3',\n",
       "  'mask': '6,7,8',\n",
       "  'num': '9',\n",
       "  'random': '1',\n",
       "  'truth_thresh': '1',\n",
       "  'type': 'yolo'},\n",
       " {'layers': '-4', 'type': 'route'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'stride': '2', 'type': 'upsample'},\n",
       " {'layers': '-1, 61', 'type': 'route'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'linear',\n",
       "  'filters': '255',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'anchors': '10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326',\n",
       "  'classes': '80',\n",
       "  'ignore_thresh': '.5',\n",
       "  'jitter': '.3',\n",
       "  'mask': '3,4,5',\n",
       "  'num': '9',\n",
       "  'random': '1',\n",
       "  'truth_thresh': '1',\n",
       "  'type': 'yolo'},\n",
       " {'layers': '-4', 'type': 'route'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'stride': '2', 'type': 'upsample'},\n",
       " {'layers': '-1, 36', 'type': 'route'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'activation': 'linear',\n",
       "  'filters': '255',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1',\n",
       "  'type': 'convolutional'},\n",
       " {'anchors': '10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326',\n",
       "  'classes': '80',\n",
       "  'ignore_thresh': '.5',\n",
       "  'jitter': '.3',\n",
       "  'mask': '0,1,2',\n",
       "  'num': '9',\n",
       "  'random': '1',\n",
       "  'truth_thresh': '1',\n",
       "  'type': 'yolo'}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#检测对配置文件的解析是否对\n",
    "parse_cfg('.\\cfg\\yolov3.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'type': 'net', 'batch': '1', 'subdivisions': '1', 'width': '416', 'height': '416', 'channels': '3', 'momentum': '0.9', 'decay': '0.0005', 'angle': '0', 'saturation': '1.5', 'exposure': '1.5', 'hue': '.1', 'learning_rate': '0.001', 'burn_in': '1000', 'max_batches': '500200', 'policy': 'steps', 'steps': '400000,450000', 'scales': '.1,.1'}, ModuleList(\n",
      "  (0): Sequential(\n",
      "    (conv_0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_0): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (conv_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_1): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    (conv_2): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_2): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (3): Sequential(\n",
      "    (conv_3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_3): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (4): Sequential(\n",
      "    (shortcut_4): EmptyLayer()\n",
      "  )\n",
      "  (5): Sequential(\n",
      "    (conv_5): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (batch_norm_5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_5): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (6): Sequential(\n",
      "    (conv_6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_6): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (7): Sequential(\n",
      "    (conv_7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_7): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (8): Sequential(\n",
      "    (shortcut_8): EmptyLayer()\n",
      "  )\n",
      "  (9): Sequential(\n",
      "    (conv_9): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_9): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (10): Sequential(\n",
      "    (conv_10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_10): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (11): Sequential(\n",
      "    (shortcut_11): EmptyLayer()\n",
      "  )\n",
      "  (12): Sequential(\n",
      "    (conv_12): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (batch_norm_12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_12): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (13): Sequential(\n",
      "    (conv_13): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_13): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (14): Sequential(\n",
      "    (conv_14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_14): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (15): Sequential(\n",
      "    (shortcut_15): EmptyLayer()\n",
      "  )\n",
      "  (16): Sequential(\n",
      "    (conv_16): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_16): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (17): Sequential(\n",
      "    (conv_17): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_17): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_17): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (18): Sequential(\n",
      "    (shortcut_18): EmptyLayer()\n",
      "  )\n",
      "  (19): Sequential(\n",
      "    (conv_19): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_19): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_19): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (20): Sequential(\n",
      "    (conv_20): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_20): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_20): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (21): Sequential(\n",
      "    (shortcut_21): EmptyLayer()\n",
      "  )\n",
      "  (22): Sequential(\n",
      "    (conv_22): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_22): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (23): Sequential(\n",
      "    (conv_23): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_23): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_23): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (24): Sequential(\n",
      "    (shortcut_24): EmptyLayer()\n",
      "  )\n",
      "  (25): Sequential(\n",
      "    (conv_25): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_25): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_25): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (26): Sequential(\n",
      "    (conv_26): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_26): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_26): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (27): Sequential(\n",
      "    (shortcut_27): EmptyLayer()\n",
      "  )\n",
      "  (28): Sequential(\n",
      "    (conv_28): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_28): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_28): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (29): Sequential(\n",
      "    (conv_29): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_29): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_29): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (30): Sequential(\n",
      "    (shortcut_30): EmptyLayer()\n",
      "  )\n",
      "  (31): Sequential(\n",
      "    (conv_31): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_31): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_31): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (32): Sequential(\n",
      "    (conv_32): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_32): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_32): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (33): Sequential(\n",
      "    (shortcut_33): EmptyLayer()\n",
      "  )\n",
      "  (34): Sequential(\n",
      "    (conv_34): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_34): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_34): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (35): Sequential(\n",
      "    (conv_35): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_35): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_35): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (36): Sequential(\n",
      "    (shortcut_36): EmptyLayer()\n",
      "  )\n",
      "  (37): Sequential(\n",
      "    (conv_37): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (batch_norm_37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_37): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (38): Sequential(\n",
      "    (conv_38): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_38): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_38): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (39): Sequential(\n",
      "    (conv_39): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_39): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_39): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (40): Sequential(\n",
      "    (shortcut_40): EmptyLayer()\n",
      "  )\n",
      "  (41): Sequential(\n",
      "    (conv_41): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_41): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_41): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (42): Sequential(\n",
      "    (conv_42): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_42): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_42): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (43): Sequential(\n",
      "    (shortcut_43): EmptyLayer()\n",
      "  )\n",
      "  (44): Sequential(\n",
      "    (conv_44): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_44): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_44): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (45): Sequential(\n",
      "    (conv_45): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_45): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_45): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (46): Sequential(\n",
      "    (shortcut_46): EmptyLayer()\n",
      "  )\n",
      "  (47): Sequential(\n",
      "    (conv_47): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_47): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_47): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (48): Sequential(\n",
      "    (conv_48): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_48): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_48): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (49): Sequential(\n",
      "    (shortcut_49): EmptyLayer()\n",
      "  )\n",
      "  (50): Sequential(\n",
      "    (conv_50): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_50): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_50): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (51): Sequential(\n",
      "    (conv_51): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_51): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_51): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (52): Sequential(\n",
      "    (shortcut_52): EmptyLayer()\n",
      "  )\n",
      "  (53): Sequential(\n",
      "    (conv_53): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_53): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_53): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (54): Sequential(\n",
      "    (conv_54): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_54): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_54): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (55): Sequential(\n",
      "    (shortcut_55): EmptyLayer()\n",
      "  )\n",
      "  (56): Sequential(\n",
      "    (conv_56): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_56): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_56): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (57): Sequential(\n",
      "    (conv_57): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_57): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_57): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (58): Sequential(\n",
      "    (shortcut_58): EmptyLayer()\n",
      "  )\n",
      "  (59): Sequential(\n",
      "    (conv_59): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_59): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_59): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (60): Sequential(\n",
      "    (conv_60): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_60): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_60): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (61): Sequential(\n",
      "    (shortcut_61): EmptyLayer()\n",
      "  )\n",
      "  (62): Sequential(\n",
      "    (conv_62): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (batch_norm_62): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_62): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (63): Sequential(\n",
      "    (conv_63): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_63): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_63): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (64): Sequential(\n",
      "    (conv_64): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_64): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_64): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (65): Sequential(\n",
      "    (shortcut_65): EmptyLayer()\n",
      "  )\n",
      "  (66): Sequential(\n",
      "    (conv_66): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_66): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_66): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (67): Sequential(\n",
      "    (conv_67): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_67): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_67): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (68): Sequential(\n",
      "    (shortcut_68): EmptyLayer()\n",
      "  )\n",
      "  (69): Sequential(\n",
      "    (conv_69): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_69): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_69): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (70): Sequential(\n",
      "    (conv_70): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_70): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_70): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (71): Sequential(\n",
      "    (shortcut_71): EmptyLayer()\n",
      "  )\n",
      "  (72): Sequential(\n",
      "    (conv_72): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_72): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_72): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (73): Sequential(\n",
      "    (conv_73): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_73): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_73): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (74): Sequential(\n",
      "    (shortcut_74): EmptyLayer()\n",
      "  )\n",
      "  (75): Sequential(\n",
      "    (conv_75): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_75): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_75): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (76): Sequential(\n",
      "    (conv_76): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_76): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_76): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (77): Sequential(\n",
      "    (conv_77): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_77): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_77): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (78): Sequential(\n",
      "    (conv_78): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_78): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_78): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (79): Sequential(\n",
      "    (conv_79): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_79): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_79): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (80): Sequential(\n",
      "    (conv_80): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_80): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_80): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (81): Sequential(\n",
      "    (conv_81): Conv2d(1024, 255, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (82): Sequential(\n",
      "    (Detection_82): DetectionLayer()\n",
      "  )\n",
      "  (83): Sequential(\n",
      "    (route_83): EmptyLayer()\n",
      "  )\n",
      "  (84): Sequential(\n",
      "    (conv_84): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_84): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_84): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (85): Sequential(\n",
      "    (upsample_85): Upsample(scale_factor=2, mode=nearest)\n",
      "  )\n",
      "  (86): Sequential(\n",
      "    (route_86): EmptyLayer()\n",
      "  )\n",
      "  (87): Sequential(\n",
      "    (conv_87): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_87): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_87): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (88): Sequential(\n",
      "    (conv_88): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_88): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_88): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (89): Sequential(\n",
      "    (conv_89): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_89): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_89): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (90): Sequential(\n",
      "    (conv_90): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_90): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_90): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (91): Sequential(\n",
      "    (conv_91): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_91): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_91): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (92): Sequential(\n",
      "    (conv_92): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_92): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_92): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (93): Sequential(\n",
      "    (conv_93): Conv2d(512, 255, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (94): Sequential(\n",
      "    (Detection_94): DetectionLayer()\n",
      "  )\n",
      "  (95): Sequential(\n",
      "    (route_95): EmptyLayer()\n",
      "  )\n",
      "  (96): Sequential(\n",
      "    (conv_96): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_96): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_96): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (97): Sequential(\n",
      "    (upsample_97): Upsample(scale_factor=2, mode=nearest)\n",
      "  )\n",
      "  (98): Sequential(\n",
      "    (route_98): EmptyLayer()\n",
      "  )\n",
      "  (99): Sequential(\n",
      "    (conv_99): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_99): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_99): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (100): Sequential(\n",
      "    (conv_100): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_100): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_100): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (101): Sequential(\n",
      "    (conv_101): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_101): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_101): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (102): Sequential(\n",
      "    (conv_102): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_102): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_102): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (103): Sequential(\n",
      "    (conv_103): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_103): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_103): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (104): Sequential(\n",
      "    (conv_104): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_104): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_104): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (105): Sequential(\n",
      "    (conv_105): Conv2d(256, 255, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (106): Sequential(\n",
      "    (Detection_106): DetectionLayer()\n",
      "  )\n",
      "))\n"
     ]
    }
   ],
   "source": [
    "#检测创建网络\n",
    "from darknet import *\n",
    "blocks = parse_cfg('cfg/yolov3.cfg')\n",
    "print(create_modules(blocks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of darknet failed: Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 246, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 369, in superreload\n",
      "    module = reload(module)\n",
      "  File \"D:\\Anaconda\\lib\\imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"D:\\Anaconda\\lib\\importlib\\__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 608, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 674, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 781, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 741, in source_to_code\n",
      "  File \"<frozen importlib._bootstrap>\", line 205, in _call_with_frames_removed\n",
      "  File \"E:\\ComputerVision\\YOLO\\darknet.py\", line 132\n",
      "    elif (x[\"type\"] == \"yolo\"):\n",
      "       ^\n",
      "SyntaxError: invalid syntax\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'type': 'net', 'batch': '1', 'subdivisions': '1', 'width': '416', 'height': '416', 'channels': '3', 'momentum': '0.9', 'decay': '0.0005', 'angle': '0', 'saturation': '1.5', 'exposure': '1.5', 'hue': '.1', 'learning_rate': '0.001', 'burn_in': '1000', 'max_batches': '500200', 'policy': 'steps', 'steps': '400000,450000', 'scales': '.1,.1'}, ModuleList(\n",
      "  (0): Sequential(\n",
      "    (conv_0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_0): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (conv_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_1): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    (conv_2): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_2): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (3): Sequential(\n",
      "    (conv_3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_3): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (4): Sequential(\n",
      "    (shortcut_4): EmptyLayer()\n",
      "  )\n",
      "  (5): Sequential(\n",
      "    (conv_5): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (batch_norm_5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_5): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (6): Sequential(\n",
      "    (conv_6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_6): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (7): Sequential(\n",
      "    (conv_7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_7): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (8): Sequential(\n",
      "    (shortcut_8): EmptyLayer()\n",
      "  )\n",
      "  (9): Sequential(\n",
      "    (conv_9): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_9): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (10): Sequential(\n",
      "    (conv_10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_10): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (11): Sequential(\n",
      "    (shortcut_11): EmptyLayer()\n",
      "  )\n",
      "  (12): Sequential(\n",
      "    (conv_12): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (batch_norm_12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_12): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (13): Sequential(\n",
      "    (conv_13): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_13): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (14): Sequential(\n",
      "    (conv_14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_14): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (15): Sequential(\n",
      "    (shortcut_15): EmptyLayer()\n",
      "  )\n",
      "  (16): Sequential(\n",
      "    (conv_16): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_16): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (17): Sequential(\n",
      "    (conv_17): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_17): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_17): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (18): Sequential(\n",
      "    (shortcut_18): EmptyLayer()\n",
      "  )\n",
      "  (19): Sequential(\n",
      "    (conv_19): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_19): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_19): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (20): Sequential(\n",
      "    (conv_20): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_20): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_20): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (21): Sequential(\n",
      "    (shortcut_21): EmptyLayer()\n",
      "  )\n",
      "  (22): Sequential(\n",
      "    (conv_22): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_22): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (23): Sequential(\n",
      "    (conv_23): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_23): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_23): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (24): Sequential(\n",
      "    (shortcut_24): EmptyLayer()\n",
      "  )\n",
      "  (25): Sequential(\n",
      "    (conv_25): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_25): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_25): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (26): Sequential(\n",
      "    (conv_26): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_26): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_26): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (27): Sequential(\n",
      "    (shortcut_27): EmptyLayer()\n",
      "  )\n",
      "  (28): Sequential(\n",
      "    (conv_28): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_28): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_28): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (29): Sequential(\n",
      "    (conv_29): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_29): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_29): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (30): Sequential(\n",
      "    (shortcut_30): EmptyLayer()\n",
      "  )\n",
      "  (31): Sequential(\n",
      "    (conv_31): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_31): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_31): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (32): Sequential(\n",
      "    (conv_32): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_32): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_32): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (33): Sequential(\n",
      "    (shortcut_33): EmptyLayer()\n",
      "  )\n",
      "  (34): Sequential(\n",
      "    (conv_34): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_34): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_34): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (35): Sequential(\n",
      "    (conv_35): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_35): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_35): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (36): Sequential(\n",
      "    (shortcut_36): EmptyLayer()\n",
      "  )\n",
      "  (37): Sequential(\n",
      "    (conv_37): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (batch_norm_37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_37): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (38): Sequential(\n",
      "    (conv_38): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_38): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_38): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (39): Sequential(\n",
      "    (conv_39): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_39): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_39): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (40): Sequential(\n",
      "    (shortcut_40): EmptyLayer()\n",
      "  )\n",
      "  (41): Sequential(\n",
      "    (conv_41): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_41): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_41): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (42): Sequential(\n",
      "    (conv_42): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_42): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_42): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (43): Sequential(\n",
      "    (shortcut_43): EmptyLayer()\n",
      "  )\n",
      "  (44): Sequential(\n",
      "    (conv_44): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_44): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_44): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (45): Sequential(\n",
      "    (conv_45): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_45): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_45): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (46): Sequential(\n",
      "    (shortcut_46): EmptyLayer()\n",
      "  )\n",
      "  (47): Sequential(\n",
      "    (conv_47): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_47): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_47): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (48): Sequential(\n",
      "    (conv_48): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_48): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_48): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (49): Sequential(\n",
      "    (shortcut_49): EmptyLayer()\n",
      "  )\n",
      "  (50): Sequential(\n",
      "    (conv_50): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_50): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_50): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (51): Sequential(\n",
      "    (conv_51): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_51): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_51): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (52): Sequential(\n",
      "    (shortcut_52): EmptyLayer()\n",
      "  )\n",
      "  (53): Sequential(\n",
      "    (conv_53): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_53): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_53): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (54): Sequential(\n",
      "    (conv_54): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_54): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_54): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (55): Sequential(\n",
      "    (shortcut_55): EmptyLayer()\n",
      "  )\n",
      "  (56): Sequential(\n",
      "    (conv_56): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_56): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_56): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (57): Sequential(\n",
      "    (conv_57): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_57): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_57): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (58): Sequential(\n",
      "    (shortcut_58): EmptyLayer()\n",
      "  )\n",
      "  (59): Sequential(\n",
      "    (conv_59): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_59): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_59): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (60): Sequential(\n",
      "    (conv_60): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_60): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_60): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (61): Sequential(\n",
      "    (shortcut_61): EmptyLayer()\n",
      "  )\n",
      "  (62): Sequential(\n",
      "    (conv_62): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (batch_norm_62): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_62): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (63): Sequential(\n",
      "    (conv_63): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_63): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_63): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (64): Sequential(\n",
      "    (conv_64): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_64): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_64): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (65): Sequential(\n",
      "    (shortcut_65): EmptyLayer()\n",
      "  )\n",
      "  (66): Sequential(\n",
      "    (conv_66): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_66): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_66): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (67): Sequential(\n",
      "    (conv_67): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_67): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_67): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (68): Sequential(\n",
      "    (shortcut_68): EmptyLayer()\n",
      "  )\n",
      "  (69): Sequential(\n",
      "    (conv_69): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_69): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_69): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (70): Sequential(\n",
      "    (conv_70): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_70): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_70): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (71): Sequential(\n",
      "    (shortcut_71): EmptyLayer()\n",
      "  )\n",
      "  (72): Sequential(\n",
      "    (conv_72): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_72): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_72): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (73): Sequential(\n",
      "    (conv_73): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_73): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_73): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (74): Sequential(\n",
      "    (shortcut_74): EmptyLayer()\n",
      "  )\n",
      "  (75): Sequential(\n",
      "    (conv_75): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_75): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_75): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (76): Sequential(\n",
      "    (conv_76): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_76): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_76): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (77): Sequential(\n",
      "    (conv_77): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_77): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_77): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (78): Sequential(\n",
      "    (conv_78): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_78): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_78): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (79): Sequential(\n",
      "    (conv_79): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_79): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_79): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (80): Sequential(\n",
      "    (conv_80): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_80): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_80): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (81): Sequential(\n",
      "    (conv_81): Conv2d(1024, 255, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (82): Sequential(\n",
      "    (Detection_82): DetectionLayer()\n",
      "  )\n",
      "  (83): Sequential(\n",
      "    (route_83): EmptyLayer()\n",
      "  )\n",
      "  (84): Sequential(\n",
      "    (conv_84): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_84): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_84): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (85): Sequential(\n",
      "    (upsample_85): Upsample(scale_factor=2, mode=nearest)\n",
      "  )\n",
      "  (86): Sequential(\n",
      "    (route_86): EmptyLayer()\n",
      "  )\n",
      "  (87): Sequential(\n",
      "    (conv_87): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_87): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_87): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (88): Sequential(\n",
      "    (conv_88): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_88): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_88): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (89): Sequential(\n",
      "    (conv_89): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_89): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_89): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (90): Sequential(\n",
      "    (conv_90): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_90): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_90): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (91): Sequential(\n",
      "    (conv_91): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_91): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_91): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (92): Sequential(\n",
      "    (conv_92): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_92): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_92): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (93): Sequential(\n",
      "    (conv_93): Conv2d(512, 255, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (94): Sequential(\n",
      "    (Detection_94): DetectionLayer()\n",
      "  )\n",
      "  (95): Sequential(\n",
      "    (route_95): EmptyLayer()\n",
      "  )\n",
      "  (96): Sequential(\n",
      "    (conv_96): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_96): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_96): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (97): Sequential(\n",
      "    (upsample_97): Upsample(scale_factor=2, mode=nearest)\n",
      "  )\n",
      "  (98): Sequential(\n",
      "    (route_98): EmptyLayer()\n",
      "  )\n",
      "  (99): Sequential(\n",
      "    (conv_99): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_99): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_99): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (100): Sequential(\n",
      "    (conv_100): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_100): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_100): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (101): Sequential(\n",
      "    (conv_101): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_101): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_101): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (102): Sequential(\n",
      "    (conv_102): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_102): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_102): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (103): Sequential(\n",
      "    (conv_103): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (batch_norm_103): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_103): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (104): Sequential(\n",
      "    (conv_104): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch_norm_104): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_104): LeakyReLU(negative_slope=0.1, inplace)\n",
      "  )\n",
      "  (105): Sequential(\n",
      "    (conv_105): Conv2d(256, 255, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (106): Sequential(\n",
      "    (Detection_106): DetectionLayer()\n",
      "  )\n",
      "))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "blocks = parse_cfg('cfg/yolov3.cfg')\n",
    "print(create_modules(blocks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of darknet failed: Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 246, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 369, in superreload\n",
      "    module = reload(module)\n",
      "  File \"D:\\Anaconda\\lib\\imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"D:\\Anaconda\\lib\\importlib\\__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 608, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 674, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 781, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 741, in source_to_code\n",
      "  File \"<frozen importlib._bootstrap>\", line 205, in _call_with_frames_removed\n",
      "  File \"E:\\ComputerVision\\YOLO\\darknet.py\", line 135\n",
      "    elif (x[\"type\"] == \"yolo\"):\n",
      "       ^\n",
      "SyntaxError: invalid syntax\n",
      "]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'filters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-2a99ab0b4f9b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprev_filters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilters\u001b[0m\u001b[1;31m#有的层没有filters怎么加呢\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0moutput_filters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'filters' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[  15.7473,   16.0189,  110.7126,  ...,    0.5069,\n",
      "             0.4354,    0.5263],\n",
      "         [  15.6137,   16.1746,  173.0657,  ...,    0.5046,\n",
      "             0.4697,    0.5124],\n",
      "         [  17.8154,   14.8297,  364.2511,  ...,    0.5793,\n",
      "             0.4500,    0.4687],\n",
      "         ...,\n",
      "         [ 412.6372,  412.0495,    9.1626,  ...,    0.5292,\n",
      "             0.4656,    0.4692],\n",
      "         [ 411.9863,  411.6248,   19.2783,  ...,    0.4350,\n",
      "             0.4629,    0.4556],\n",
      "         [ 412.3563,  411.9576,   25.9322,  ...,    0.4133,\n",
      "             0.5264,    0.4510]]])\n"
     ]
    }
   ],
   "source": [
    "#测试反向传播\n",
    "'''\n",
    "对于批量中的图像，我们会有一个 100647×85 的表，它的每一行表示一个边界框（4 个边界框属性、1 个 objectness 分数和 80 个类别分数）\n",
    "'''\n",
    "model = Darknet(\"cfg/yolov3.cfg\")\n",
    "inp = get_test_input()\n",
    "pred = model(inp,False)\n",
    "print (pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading network.....\n",
      "Network successfully loaded\n",
      "E:\\ComputerVision\\YOLO\\dog-cycle-car.png predicted in  3.333 seconds\n",
      "Objects Detected:    bicycle truck dog\n",
      "----------------------------------------------------------\n",
      "SUMMARY\n",
      "----------------------------------------------------------\n",
      "Task                     : Time Taken (in seconds)\n",
      "\n",
      "Reading addresses        : 0.000\n",
      "Loading batch            : 0.020\n",
      "Detection (1 images)     : 3.336\n",
      "Output Processing        : 0.000\n",
      "Drawing Boxes            : 1.360\n",
      "Average time_per_img     : 4.716\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "%run detector.py --images dog-cycle-car.png --det det"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = torch.FloatTensor([[1,2],[4,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-e20c82df8fd1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprediction\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"
     ]
    }
   ],
   "source": [
    "prediction[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
